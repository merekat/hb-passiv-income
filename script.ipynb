{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c9a2fb",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9fe259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d3fcb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Dow Jones</th>\n",
       "      <th>S&amp;P-500</th>\n",
       "      <th>S&amp;P/TSX Composite</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>FTSE 100</th>\n",
       "      <th>Bovespa</th>\n",
       "      <th>Shanghai Composite</th>\n",
       "      <th>Korea Composite</th>\n",
       "      <th>NIKKEI 225</th>\n",
       "      <th>IBEX 35</th>\n",
       "      <th>S&amp;P/ASX 50</th>\n",
       "      <th>OMX Stockholm</th>\n",
       "      <th>HANG SENG</th>\n",
       "      <th>BSE SENSEX</th>\n",
       "      <th>Dax</th>\n",
       "      <th>FTSE All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955</td>\n",
       "      <td>19.445328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.631374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.545620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956</td>\n",
       "      <td>2.266585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.306617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.999977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957</td>\n",
       "      <td>-12.769536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-23.516293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.133008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>33.959926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.754762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.919984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959</td>\n",
       "      <td>16.398527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.345578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.663857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1960</td>\n",
       "      <td>-9.342617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.864563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.073839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1961</td>\n",
       "      <td>18.712757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.657708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.593679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1962</td>\n",
       "      <td>-10.810515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.253264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.849504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1963</td>\n",
       "      <td>16.998927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.720377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.146019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.178760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1964</td>\n",
       "      <td>14.572384</td>\n",
       "      <td>12.969875</td>\n",
       "      <td>21.462623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.390127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.046836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  Dow Jones    S&P-500  S&P/TSX Composite  CAC 40  FTSE 100  Bovespa  \\\n",
       "0  1955  19.445328        NaN          22.631374     NaN       NaN      NaN   \n",
       "1  1956   2.266585        NaN           5.306617     NaN       NaN      NaN   \n",
       "2  1957 -12.769536        NaN         -23.516293     NaN       NaN      NaN   \n",
       "3  1958  33.959926        NaN          26.754762     NaN       NaN      NaN   \n",
       "4  1959  16.398527        NaN           1.345578     NaN       NaN      NaN   \n",
       "5  1960  -9.342617        NaN          -1.864563     NaN       NaN      NaN   \n",
       "6  1961  18.712757        NaN          28.657708     NaN       NaN      NaN   \n",
       "7  1962 -10.810515        NaN         -10.253264     NaN       NaN      NaN   \n",
       "8  1963  16.998927        NaN          11.720377     NaN       NaN      NaN   \n",
       "9  1964  14.572384  12.969875          21.462623     NaN       NaN      NaN   \n",
       "\n",
       "   Shanghai Composite  Korea Composite  NIKKEI 225  IBEX 35  S&P/ASX 50  \\\n",
       "0                 NaN              NaN   19.545620      NaN         NaN   \n",
       "1                 NaN              NaN   28.999977      NaN         NaN   \n",
       "2                 NaN              NaN  -14.133008      NaN         NaN   \n",
       "3                 NaN              NaN   40.919984      NaN         NaN   \n",
       "4                 NaN              NaN   31.663857      NaN         NaN   \n",
       "5                 NaN              NaN   55.073839      NaN         NaN   \n",
       "6                 NaN              NaN    5.593679      NaN         NaN   \n",
       "7                 NaN              NaN   -0.849504      NaN         NaN   \n",
       "8                 NaN              NaN  -13.146019      NaN         NaN   \n",
       "9                 NaN              NaN   -1.390127      NaN         NaN   \n",
       "\n",
       "   OMX Stockholm  HANG SENG  BSE SENSEX  Dax   FTSE All  \n",
       "0            NaN        NaN         NaN  NaN        NaN  \n",
       "1            NaN        NaN         NaN  NaN        NaN  \n",
       "2            NaN        NaN         NaN  NaN        NaN  \n",
       "3            NaN        NaN         NaN  NaN        NaN  \n",
       "4            NaN        NaN         NaN  NaN        NaN  \n",
       "5            NaN        NaN         NaN  NaN        NaN  \n",
       "6            NaN        NaN         NaN  NaN        NaN  \n",
       "7            NaN        NaN         NaN  NaN        NaN  \n",
       "8            NaN        NaN         NaN  NaN  15.178760  \n",
       "9            NaN        NaN         NaN  NaN -10.046836  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load historical treasury data\n",
    "file_path = \"./data/Anleihen und Indizes historische Zinsen.xlsx\"\n",
    "df_anleihen = pd.read_excel(file_path, sheet_name=\"Anleihen\", skiprows=2)\n",
    "\n",
    "# Load historical indices data\n",
    "df_etf = pd.read_excel(file_path, sheet_name=\"Indizes\")\n",
    "\n",
    "df_anleihen = df_anleihen.drop(df_anleihen.columns[[6, 11, 12, 13, 14, 15]], axis=1)\n",
    "df_anleihen.columns = [\"date\", \"Australien\", \"Kanada\", \"Frankreich\", \"Deutschland\", \"Japan\", \"Spanien\", \"Schweiz\", \"GroÃŸbritannien\", \"USA\"]\n",
    "\n",
    "df_etf.columns = [\"date\", \"Dow Jones\", \"S&P-500\", \"S&P/TSX Composite\", \"CAC 40\", \"FTSE 100\", \"Bovespa\", \"Shanghai Composite\", \"Korea Composite\", \"NIKKEI 225\", \"IBEX 35\", \"S&P/ASX 50\", \"OMX Stockholm\", \"HANG SENG\", \"BSE SENSEX\", \"Dax\", \"FTSE All\"]\n",
    "\n",
    "df_etf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be72d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the range of years\n",
    "year_range = range(1, 31) \n",
    "\n",
    "# Initialize the structure for the JSON\n",
    "json_structure = {\n",
    "    \"assets\": []\n",
    "}\n",
    "\n",
    "# Function to process columns and add them to the JSON structure\n",
    "def process_columns(df, category):\n",
    "    for column_name in df.columns:\n",
    "        if column_name == 'date':\n",
    "            continue  \n",
    "\n",
    "        growth_column = df[column_name]\n",
    "        date_column = df['date']\n",
    "\n",
    "        # Add a new asset entry for the current column\n",
    "        asset_entry = {\n",
    "            \"category\": category,\n",
    "            \"label\": f\"{column_name}\",\n",
    "            \"kennung\": f\"{category} {column_name}\",\n",
    "            \"id\": f\"{category} {column_name}\",\n",
    "            \"data\": [] \n",
    "        }\n",
    "\n",
    "        # Iterate through all values of year\n",
    "        for year in year_range:\n",
    "            \n",
    "            highest_value = float('-inf')\n",
    "            lowest_value = float('inf')\n",
    "            highest_year = None\n",
    "            lowest_year = None\n",
    "            highest_values_list = []  \n",
    "            lowest_values_list = [] \n",
    "            median_values_list = []  \n",
    "            values_with_years = [] \n",
    "\n",
    "            # Iterate through all rows where there are numbers\n",
    "            valid_growths = growth_column.dropna()\n",
    "            valid_dates = date_column[~growth_column.isna()]  \n",
    "\n",
    "            for i in range(len(valid_growths) - year + 1): \n",
    "                value = 1\n",
    "                growth_array = [] \n",
    "                for growth in valid_growths[i:i + year]:\n",
    "                    value *= (1 + growth / 100)  \n",
    "                    growth_array.append(round(growth, 2))  \n",
    "                \n",
    "                values_with_years.append((value, valid_dates.iloc[i], growth_array))  \n",
    "                if value > highest_value:\n",
    "                    highest_value = value\n",
    "                    highest_year = valid_dates.iloc[i]\n",
    "                    highest_values_list = growth_array  \n",
    "                if value < lowest_value:\n",
    "                    lowest_value = value\n",
    "                    lowest_year = valid_dates.iloc[i]\n",
    "                    lowest_values_list = growth_array  \n",
    "\n",
    "            # Calculate the median value and find its corresponding year and array\n",
    "            if values_with_years:  \n",
    "                sorted_values = sorted(values_with_years, key=lambda v: v[0])\n",
    "                median_index = len(sorted_values) // 2\n",
    "                median_value, median_year, median_values_list = sorted_values[median_index]\n",
    "\n",
    "                # Create dictionaries for max, median, and min arrays\n",
    "                max_dict = {\n",
    "                    \"type\": f\"max\",\n",
    "                    \"duration\": f\"{year}\",\n",
    "                    \"year\": str(highest_year),\n",
    "                    \"growth_array\": highest_values_list\n",
    "                }\n",
    "                median_dict = {\n",
    "                    \"type\": f\"median\",\n",
    "                    \"duration\": f\"{year}\",\n",
    "                    \"year\": str(median_year),\n",
    "                    \"growth_array\": median_values_list\n",
    "                }\n",
    "                min_dict = {\n",
    "                    \"type\": f\"min\",\n",
    "                    \"duration\": f\"{year}\",\n",
    "                    \"year\": str(lowest_year),\n",
    "                    \"growth_array\": lowest_values_list\n",
    "                }\n",
    "\n",
    "                # Append the dictionaries to the \"data\" key in the asset entry\n",
    "                asset_entry[\"data\"].extend([max_dict, median_dict, min_dict])\n",
    "            else:\n",
    "                print(f\"No valid values for column '{column_name}' and year = {year}. Skipping...\")\n",
    "\n",
    "        # Append the asset entry to the JSON structure\n",
    "        json_structure[\"assets\"].append(asset_entry)\n",
    "\n",
    "# Process both `df_anleihen` and `df_etf`\n",
    "process_columns(df_anleihen, \"Anleihe\")\n",
    "process_columns(df_etf, \"Index\")\n",
    "\n",
    "# Save the JSON structure to a file\n",
    "with open(\"export/data.json\", \"w\") as json_file:\n",
    "    json.dump(json_structure, json_file, separators=(\",\", \":\")) \n",
    "\n",
    "print(\"JSON file saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
