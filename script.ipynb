{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c9a2fb",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9fe259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e901aa1",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3fcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical data\n",
    "file_path_anleihen_indices = \"./data/Anleihen und Indizes historische Zinsen.xlsx\"\n",
    "file_path_festgeld_tagesgeld = \"./data/Handelsblatt_Spezial.xlsx\"\n",
    "file_path_etf = \"./data/ETFs.xlsx\"\n",
    "file_path_inflation = \"./data/Inflation_historisch_final.xlsx\"\n",
    "\n",
    "df_anleihen = pd.read_excel(file_path_anleihen_indices, sheet_name=\"Anleihen\", skiprows=2)\n",
    "df_indices = pd.read_excel(file_path_anleihen_indices, sheet_name=\"Indizes\")\n",
    "df_festgeld_tagesgeld= pd.read_excel(file_path_festgeld_tagesgeld, sheet_name=\"Monatswert\", skiprows=1)\n",
    "df_etf= pd.read_excel(file_path_etf, sheet_name=\"ETFs\")\n",
    "df_inflation= pd.read_excel(file_path_inflation, skiprows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b26b97",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaca307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anleihen = df_anleihen.drop(df_anleihen.columns[[6, 11, 12, 13, 14, 15]], axis=1)\n",
    "df_anleihen.columns = [\"date\", \"Australien\", \"Kanada\", \"Frankreich\", \"Deutschland\", \"Japan\", \"Spanien\", \"Schweiz\", \"Großbritannien\", \"USA\"]\n",
    "\n",
    "df_indices.columns = [\"date\", \"Dow Jones\", \"S&P-500\", \"S&P/TSX Composite\", \"CAC 40\", \"FTSE 100\", \"Bovespa\", \"Shanghai Composite\", \"Korea Composite\", \"NIKKEI 225\", \"IBEX 35\", \"S&P/ASX 50\", \"OMX Stockholm\", \"HANG SENG\", \"BSE SENSEX\", \"DAX\", \"FTSE All\"]\n",
    "\n",
    "df_festgeld_tagesgeld.columns = ['date', '6 Monate', '1 Jahr', '2 Jahre', '5 Jahre', '10 Jahre', 'Tagesgeld', \"Inflation_Deutschland\"]\n",
    "df_festgeld_tagesgeld['date'] = pd.to_datetime(df_festgeld_tagesgeld['date'])\n",
    "df_festgeld_tagesgeld['date'] = df_festgeld_tagesgeld['date'].dt.year\n",
    "\n",
    "df_etf.columns = [\"date\", \"MSCI World\", \"MSCI Emerging Markets\", \"FTSE All World\", \"S&P Europe 600\", \"NASDAQ 100\"]\n",
    "\n",
    "df_inflation = df_inflation.drop(df_inflation.columns[[6, 7, 8, 9]], axis=1)\n",
    "df_inflation.columns = [\"date\", \"Australien\", \"Kanada\", \"Deutschland\", \"Frankreich\", \"Japan\", \"Spanien\", \"Schweiz\", \"Großbritannien\", \"USA\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615aa78",
   "metadata": {},
   "source": [
    "##### Reduce Anleihen by inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3f30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the 'date' column\n",
    "df_anleihen['date'] = df_anleihen['date'].astype(str).str.extract(r'(\\d{4})')[0]\n",
    "df_inflation['date'] = df_inflation['date'].astype(str).str.extract(r'(\\d{4})')[0]\n",
    "\n",
    "# Convert the extracted year to datetime format\n",
    "df_anleihen['date'] = pd.to_datetime(df_anleihen['date'], format='%Y', errors='coerce')\n",
    "df_inflation['date'] = pd.to_datetime(df_inflation['date'], format='%Y', errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df_anleihen = df_anleihen.dropna(subset=['date'])\n",
    "df_inflation = df_inflation.dropna(subset=['date'])\n",
    "\n",
    "df_anleihen.set_index('date', inplace=True)\n",
    "df_inflation.set_index('date', inplace=True)\n",
    "\n",
    "# Reorder the columns in df_inflation to match the order of columns in df_anleihen\n",
    "df_inflation = df_inflation[df_anleihen.columns]\n",
    "\n",
    "# Subtract values in df_inflation from df_anleihen where both values exist\n",
    "df_inflation = df_anleihen.subtract(df_inflation, fill_value=np.nan)\n",
    "\n",
    "# Reset the index to bring 'date' back as a column and convert it to year format\n",
    "df_inflation.reset_index(inplace=True)\n",
    "df_inflation['date'] = df_inflation['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7009705b",
   "metadata": {},
   "source": [
    "##### Reduce Tages- & Festgeld by inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2851d17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>6 Monate</th>\n",
       "      <th>1 Jahr</th>\n",
       "      <th>2 Jahre</th>\n",
       "      <th>5 Jahre</th>\n",
       "      <th>10 Jahre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994</td>\n",
       "      <td>1.255601</td>\n",
       "      <td>1.629010</td>\n",
       "      <td>2.358809</td>\n",
       "      <td>3.071457</td>\n",
       "      <td>3.635168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>1.931374</td>\n",
       "      <td>2.279073</td>\n",
       "      <td>3.271378</td>\n",
       "      <td>4.510041</td>\n",
       "      <td>5.138240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996</td>\n",
       "      <td>1.305996</td>\n",
       "      <td>1.461607</td>\n",
       "      <td>2.337054</td>\n",
       "      <td>3.688200</td>\n",
       "      <td>4.763008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.829367</td>\n",
       "      <td>1.044085</td>\n",
       "      <td>1.679422</td>\n",
       "      <td>2.852342</td>\n",
       "      <td>3.882231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>2.074893</td>\n",
       "      <td>2.310220</td>\n",
       "      <td>2.860354</td>\n",
       "      <td>3.587562</td>\n",
       "      <td>4.332839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999</td>\n",
       "      <td>1.966446</td>\n",
       "      <td>2.125932</td>\n",
       "      <td>2.609831</td>\n",
       "      <td>3.296242</td>\n",
       "      <td>4.043898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>1.925889</td>\n",
       "      <td>2.245995</td>\n",
       "      <td>2.920938</td>\n",
       "      <td>3.635598</td>\n",
       "      <td>4.194538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.434226</td>\n",
       "      <td>1.582802</td>\n",
       "      <td>2.043698</td>\n",
       "      <td>2.543537</td>\n",
       "      <td>3.058751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002</td>\n",
       "      <td>1.249279</td>\n",
       "      <td>1.478143</td>\n",
       "      <td>2.021159</td>\n",
       "      <td>2.760313</td>\n",
       "      <td>3.351631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.918918</td>\n",
       "      <td>1.031854</td>\n",
       "      <td>1.388819</td>\n",
       "      <td>2.207701</td>\n",
       "      <td>3.074446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  6 Monate    1 Jahr   2 Jahre   5 Jahre  10 Jahre\n",
       "0  1994  1.255601  1.629010  2.358809  3.071457  3.635168\n",
       "1  1995  1.931374  2.279073  3.271378  4.510041  5.138240\n",
       "2  1996  1.305996  1.461607  2.337054  3.688200  4.763008\n",
       "3  1997  0.829367  1.044085  1.679422  2.852342  3.882231\n",
       "4  1998  2.074893  2.310220  2.860354  3.587562  4.332839\n",
       "5  1999  1.966446  2.125932  2.609831  3.296242  4.043898\n",
       "6  2000  1.925889  2.245995  2.920938  3.635598  4.194538\n",
       "7  2001  1.434226  1.582802  2.043698  2.543537  3.058751\n",
       "8  2002  1.249279  1.478143  2.021159  2.760313  3.351631\n",
       "9  2003  0.918918  1.031854  1.388819  2.207701  3.074446"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all columns except 'date' to numeric, coercing errors to NaN\n",
    "numeric_columns = df_festgeld_tagesgeld.columns.difference(['date'])\n",
    "df_festgeld_tagesgeld[numeric_columns] = df_festgeld_tagesgeld[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Group by date and calculate the yearly values\n",
    "def calculate_yearly_growth(group):\n",
    "    results = {}\n",
    "    for column in group.columns:\n",
    "        count = group[column].count()\n",
    "        if count == 0:  \n",
    "            results[column] = np.nan\n",
    "        else:\n",
    "            results[column] = (np.prod(group[column].dropna() + 1) ** (1 / count)) - 1\n",
    "    return pd.Series(results)\n",
    "\n",
    "# Group by year and calculate the yearly values\n",
    "df_festgeld_tagesgeld_yearly = df_festgeld_tagesgeld.groupby('date')[numeric_columns].apply(calculate_yearly_growth).reset_index()\n",
    "\n",
    "# Ensure the 'date' column remains in year format\n",
    "df_festgeld_tagesgeld_yearly['date'] = df_festgeld_tagesgeld_yearly['date'].astype(int)\n",
    "\n",
    "# Subtract the value in 'Inflation_Deutschland' from every other column in the same row\n",
    "df_festgeld_tagesgeld_yearly[numeric_columns] = df_festgeld_tagesgeld_yearly[numeric_columns].sub(\n",
    "    df_festgeld_tagesgeld_yearly['Inflation_Deutschland'], axis=0\n",
    ")\n",
    "\n",
    "# Drop the 'Inflation_Deutschland' column\n",
    "df_festgeld_tagesgeld_yearly = df_festgeld_tagesgeld_yearly.drop(columns=['Inflation_Deutschland'])\n",
    "\n",
    "# Split into df_festgeld and df_tagesgeld\n",
    "df_festgeld = df_festgeld_tagesgeld_yearly[['date', '6 Monate', '1 Jahr', '2 Jahre', '5 Jahre', '10 Jahre']]\n",
    "df_tagesgeld = df_festgeld_tagesgeld_yearly[['date', 'Tagesgeld']]\n",
    "\n",
    "# Display the resulting DataFrames\n",
    "df_festgeld.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c564d5",
   "metadata": {},
   "source": [
    "##### Reduce Indices by inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34942957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Dow Jones</th>\n",
       "      <th>S&amp;P-500</th>\n",
       "      <th>S&amp;P/TSX Composite</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>FTSE 100</th>\n",
       "      <th>Bovespa</th>\n",
       "      <th>Shanghai Composite</th>\n",
       "      <th>Korea Composite</th>\n",
       "      <th>NIKKEI 225</th>\n",
       "      <th>IBEX 35</th>\n",
       "      <th>S&amp;P/ASX 50</th>\n",
       "      <th>OMX Stockholm</th>\n",
       "      <th>HANG SENG</th>\n",
       "      <th>BSE SENSEX</th>\n",
       "      <th>DAX</th>\n",
       "      <th>FTSE All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955</td>\n",
       "      <td>16.348661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.534707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.448953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956</td>\n",
       "      <td>0.604085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.644117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.337477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957</td>\n",
       "      <td>-13.077036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-23.823793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.440508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>33.384093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.178929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.344151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959</td>\n",
       "      <td>13.075194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.977755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.340524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1960</td>\n",
       "      <td>-12.001308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.523254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.415148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1961</td>\n",
       "      <td>15.900981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.845932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.781903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1962</td>\n",
       "      <td>-13.557575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.000324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.596564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1963</td>\n",
       "      <td>14.236096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.957547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.908850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.415930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1964</td>\n",
       "      <td>11.664629</td>\n",
       "      <td>10.06212</td>\n",
       "      <td>18.554869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.297882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.954591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  Dow Jones   S&P-500  S&P/TSX Composite  CAC 40  FTSE 100  Bovespa  \\\n",
       "0  1955  16.348661       NaN          19.534707     NaN       NaN      NaN   \n",
       "1  1956   0.604085       NaN           3.644117     NaN       NaN      NaN   \n",
       "2  1957 -13.077036       NaN         -23.823793     NaN       NaN      NaN   \n",
       "3  1958  33.384093       NaN          26.178929     NaN       NaN      NaN   \n",
       "4  1959  13.075194       NaN          -1.977755     NaN       NaN      NaN   \n",
       "5  1960 -12.001308       NaN          -4.523254     NaN       NaN      NaN   \n",
       "6  1961  15.900981       NaN          25.845932     NaN       NaN      NaN   \n",
       "7  1962 -13.557575       NaN         -13.000324     NaN       NaN      NaN   \n",
       "8  1963  14.236096       NaN           8.957547     NaN       NaN      NaN   \n",
       "9  1964  11.664629  10.06212          18.554869     NaN       NaN      NaN   \n",
       "\n",
       "   Shanghai Composite  Korea Composite  NIKKEI 225  IBEX 35  S&P/ASX 50  \\\n",
       "0                 NaN              NaN   16.448953      NaN         NaN   \n",
       "1                 NaN              NaN   27.337477      NaN         NaN   \n",
       "2                 NaN              NaN  -14.440508      NaN         NaN   \n",
       "3                 NaN              NaN   40.344151      NaN         NaN   \n",
       "4                 NaN              NaN   28.340524      NaN         NaN   \n",
       "5                 NaN              NaN   52.415148      NaN         NaN   \n",
       "6                 NaN              NaN    2.781903      NaN         NaN   \n",
       "7                 NaN              NaN   -3.596564      NaN         NaN   \n",
       "8                 NaN              NaN  -15.908850      NaN         NaN   \n",
       "9                 NaN              NaN   -4.297882      NaN         NaN   \n",
       "\n",
       "   OMX Stockholm  HANG SENG  BSE SENSEX  DAX   FTSE All  \n",
       "0            NaN        NaN         NaN  NaN        NaN  \n",
       "1            NaN        NaN         NaN  NaN        NaN  \n",
       "2            NaN        NaN         NaN  NaN        NaN  \n",
       "3            NaN        NaN         NaN  NaN        NaN  \n",
       "4            NaN        NaN         NaN  NaN        NaN  \n",
       "5            NaN        NaN         NaN  NaN        NaN  \n",
       "6            NaN        NaN         NaN  NaN        NaN  \n",
       "7            NaN        NaN         NaN  NaN        NaN  \n",
       "8            NaN        NaN         NaN  NaN  12.415930  \n",
       "9            NaN        NaN         NaN  NaN -12.954591  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the 'date' column in df_inflation\n",
    "df_inflation['date'] = df_inflation['date'].astype(str).str.extract(r'(\\d{4})')[0]  # Extract the year\n",
    "df_inflation['date'] = pd.to_datetime(df_inflation['date'], format='%Y', errors='coerce')  # Convert to datetime\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df_inflation = df_inflation.dropna(subset=['date'])\n",
    "\n",
    "# Ensure the 'date' column in df_indices is in datetime format\n",
    "df_indices['date'] = pd.to_datetime(df_indices['date'], format='%Y')  # Convert year-only format to datetime\n",
    "df_indices['date'] = df_indices['date'].dt.strftime('%Y-01-01')  # Standardize to 'YYYY-01-01'\n",
    "df_indices['date'] = pd.to_datetime(df_indices['date'])  # Convert back to datetime\n",
    "\n",
    "# Merge df_indices with the 'USA' column of df_inflation on the 'date' column\n",
    "df_indices = pd.merge(df_indices, df_inflation[['date', 'USA']], on='date', how='left')\n",
    "\n",
    "# Subtract the 'USA' column from all other columns in df_indices\n",
    "numeric_columns_indices = df_indices.columns.difference(['date', 'USA'])\n",
    "df_indices[numeric_columns_indices] = df_indices[numeric_columns_indices].sub(df_indices['USA'], axis=0)\n",
    "\n",
    "# Drop the 'USA' column after adjustment\n",
    "df_indices = df_indices.drop(columns=['USA'])\n",
    "\n",
    "# Extract the year from the 'date' column\n",
    "df_indices['date'] = df_indices['date'].dt.year\n",
    "df_inflation['date'] = df_inflation['date'].dt.year\n",
    "\n",
    "# Display the reduced DataFrame\n",
    "df_indices.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2886bf",
   "metadata": {},
   "source": [
    "##### Reduce ETFs by inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d63ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>MSCI World</th>\n",
       "      <th>MSCI Emerging Markets</th>\n",
       "      <th>FTSE All World</th>\n",
       "      <th>S&amp;P Europe 600</th>\n",
       "      <th>NASDAQ 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>-3.493078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971</td>\n",
       "      <td>17.697553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972</td>\n",
       "      <td>20.610613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1973</td>\n",
       "      <td>-15.170576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1974</td>\n",
       "      <td>-20.982649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1975</td>\n",
       "      <td>35.651389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1976</td>\n",
       "      <td>12.843800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1977</td>\n",
       "      <td>1.084209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1978</td>\n",
       "      <td>17.437325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1979</td>\n",
       "      <td>14.482026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1980</td>\n",
       "      <td>29.810701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1981</td>\n",
       "      <td>-6.880959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1982</td>\n",
       "      <td>4.402164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1983</td>\n",
       "      <td>15.387181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1984</td>\n",
       "      <td>-2.363674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1985</td>\n",
       "      <td>34.691791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1986</td>\n",
       "      <td>37.015037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.115548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1987</td>\n",
       "      <td>12.043637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.981072</td>\n",
       "      <td>5.780396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1988</td>\n",
       "      <td>19.182559</td>\n",
       "      <td>35.658907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.693933</td>\n",
       "      <td>8.731907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date  MSCI World  MSCI Emerging Markets  FTSE All World  S&P Europe 600  \\\n",
       "0   1969         NaN                    NaN             NaN             NaN   \n",
       "1   1970   -3.493078                    NaN             NaN             NaN   \n",
       "2   1971   17.697553                    NaN             NaN             NaN   \n",
       "3   1972   20.610613                    NaN             NaN             NaN   \n",
       "4   1973  -15.170576                    NaN             NaN             NaN   \n",
       "5   1974  -20.982649                    NaN             NaN             NaN   \n",
       "6   1975   35.651389                    NaN             NaN             NaN   \n",
       "7   1976   12.843800                    NaN             NaN             NaN   \n",
       "8   1977    1.084209                    NaN             NaN             NaN   \n",
       "9   1978   17.437325                    NaN             NaN             NaN   \n",
       "10  1979   14.482026                    NaN             NaN             NaN   \n",
       "11  1980   29.810701                    NaN             NaN             NaN   \n",
       "12  1981   -6.880959                    NaN             NaN             NaN   \n",
       "13  1982    4.402164                    NaN             NaN             NaN   \n",
       "14  1983   15.387181                    NaN             NaN             NaN   \n",
       "15  1984   -2.363674                    NaN             NaN             NaN   \n",
       "16  1985   34.691791                    NaN             NaN             NaN   \n",
       "17  1986   37.015037                    NaN             NaN             NaN   \n",
       "18  1987   12.043637                    NaN             NaN       -1.981072   \n",
       "19  1988   19.182559              35.658907             NaN        4.693933   \n",
       "\n",
       "    NASDAQ 100  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13         NaN  \n",
       "14         NaN  \n",
       "15         NaN  \n",
       "16         NaN  \n",
       "17    1.115548  \n",
       "18    5.780396  \n",
       "19    8.731907  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the 'date' column in df_etf is in year format to match df_inflation\n",
    "df_etf['date'] = pd.to_datetime(df_etf['date'], format='%Y', errors='coerce')  # Convert year-only format to datetime\n",
    "df_etf['date'] = df_etf['date'].dt.year  # Extract only the year\n",
    "\n",
    "# Ensure the 'date' column in df_inflation is in year format\n",
    "df_inflation['date'] = pd.to_datetime(df_inflation['date'], format='%Y', errors='coerce')  # Convert year-only format to datetime\n",
    "df_inflation['date'] = df_inflation['date'].dt.year  # Extract only the year\n",
    "\n",
    "# Merge df_etf with the 'USA' column of df_inflation on the 'date' column\n",
    "df_etf = pd.merge(df_etf, df_inflation[['date', 'USA']], on='date', how='left')\n",
    "\n",
    "# Subtract the 'USA' column from all other columns in df_etf\n",
    "numeric_columns_etf = df_etf.columns.difference(['date', 'USA'])\n",
    "df_etf[numeric_columns_etf] = df_etf[numeric_columns_etf].sub(df_etf['USA'], axis=0)\n",
    "\n",
    "# Drop the 'USA' column after adjustment\n",
    "df_etf = df_etf.drop(columns=['USA'])\n",
    "\n",
    "# Display the reduced DataFrame\n",
    "df_etf.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fafca9",
   "metadata": {},
   "source": [
    "## Restructuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be72d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of years\n",
    "year_range = range(1, 31)  \n",
    "\n",
    "# Initialize the structure for the JSON\n",
    "json_structure = {\n",
    "    \"assets\": []\n",
    "}\n",
    "\n",
    "country_dict = {'MSCI World' : 'Weltweit',  'MSCI Emerging Markets' : 'Schwellenländer', 'FTSE All World' : 'Weltweit',\n",
    "       'S&P Europe 600' : 'Europa', 'Dow Jones' : 'USA', 'S&P-500' : 'USA', 'CAC 40' : 'Frankreich', 'FTSE 100' : 'Großbritannien',\n",
    "       'Shanghai Composite' : 'China', 'Korea Composite' : 'Südkorea', 'NIKKEI 225' : 'Japan', 'HANG SENG' : 'Hongkong',\n",
    "       'BSE SENSEX' : 'Indien', 'DAX' : 'Deutschland', 'FTSE All-Share' : 'Großbritannien'\n",
    "       }\n",
    "\n",
    "# Define the function to convert numpy types and pandas.Timestamp to native Python types for JSON serialization\n",
    "def convert_numpy_types(obj):\n",
    "    if isinstance(obj, (np.int64, np.int32)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, pd.Timestamp):  \n",
    "        return obj.strftime('%Y')  \n",
    "    else:\n",
    "        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "# Function to process columns and add them to the JSON structure\n",
    "def process_columns(df, category, date_column_name=\"date\"):\n",
    "    for column_name in df.columns:\n",
    "        if column_name == date_column_name:\n",
    "            continue  \n",
    "\n",
    "        growth_column = df[column_name]\n",
    "        date_column = df[date_column_name]\n",
    "\n",
    "        # Determine the category dynamically for Festgeld and Tagesgeld\n",
    "        if \"Festgeld\" in column_name:\n",
    "            column_category = \"Festgeld\"\n",
    "        elif \"Tagesgeld\" in column_name:\n",
    "            column_category = \"Tagesgeld\"\n",
    "        else:\n",
    "            column_category = category  \n",
    "\n",
    "        # Determine the country dynamically for indices\n",
    "        country_name = country_dict.get(column_name, \"Unknown\")  # Default to \"Unknown\" if not found\n",
    "\n",
    "        # Add a new asset entry for the current column\n",
    "        asset_entry = {\n",
    "            \"category\": column_category,\n",
    "            \"label\": f\"{column_name}\",\n",
    "            \"kennung\": f\"{column_category} {column_name}\",\n",
    "            \"id\": f\"{column_category}_{column_name}\",\n",
    "            \"country\": country_name, \n",
    "            \"data\": [] \n",
    "        }\n",
    "\n",
    "        # Iterate through all values of year\n",
    "        for year in year_range:\n",
    "            \n",
    "            highest_value = float('-inf')\n",
    "            lowest_value = float('inf')\n",
    "            highest_year = None\n",
    "            lowest_year = None\n",
    "            highest_values_list = []  \n",
    "            lowest_values_list = [] \n",
    "            median_values_list = []  \n",
    "            values_with_years = [] \n",
    "\n",
    "            # Iterate through all rows where there are numbers\n",
    "            valid_growths = growth_column.dropna()\n",
    "            valid_dates = date_column[~growth_column.isna()]  \n",
    "\n",
    "            for i in range(len(valid_growths) - year + 1): \n",
    "                value = 1\n",
    "                growth_array = [] \n",
    "                for growth in valid_growths[i:i + year]:\n",
    "                    value *= (1 + growth / 100)  \n",
    "                    growth_array.append(round(growth, 2))  \n",
    "                \n",
    "                values_with_years.append((value, valid_dates.iloc[i], growth_array))  \n",
    "                if value > highest_value:\n",
    "                    highest_value = value\n",
    "                    highest_year = valid_dates.iloc[i]\n",
    "                    highest_values_list = growth_array  \n",
    "                if value < lowest_value:\n",
    "                    lowest_value = value\n",
    "                    lowest_year = valid_dates.iloc[i]\n",
    "                    lowest_values_list = growth_array  \n",
    "\n",
    "            # Calculate the median value and find its corresponding year and array\n",
    "            if values_with_years:  \n",
    "                sorted_values = sorted(values_with_years, key=lambda v: v[0])\n",
    "                median_index = len(sorted_values) // 2\n",
    "                median_value, median_year, median_values_list = sorted_values[median_index]\n",
    "\n",
    "                # Create dictionaries for max, median, and min arrays\n",
    "                max_dict = {\n",
    "                    \"type\": \"max\",\n",
    "                    \"duration\": year, \n",
    "                    \"year\": highest_year,  \n",
    "                    \"growth_array\": highest_values_list\n",
    "                }\n",
    "                median_dict = {\n",
    "                    \"type\": \"median\",\n",
    "                    \"duration\": year,  \n",
    "                    \"year\": median_year, \n",
    "                    \"growth_array\": median_values_list\n",
    "                }\n",
    "                min_dict = {\n",
    "                    \"type\": \"min\",\n",
    "                    \"duration\": year, \n",
    "                    \"year\": lowest_year, \n",
    "                    \"growth_array\": lowest_values_list\n",
    "                }\n",
    "\n",
    "                # Append the dictionaries to the \"data\" key in the asset entry\n",
    "                asset_entry[\"data\"].extend([max_dict, median_dict, min_dict])\n",
    "            else:\n",
    "                print(f\"No valid values for column '{column_name}' and year = {year}. Skipping...\")\n",
    "\n",
    "        # Append the asset entry to the JSON structure\n",
    "        json_structure[\"assets\"].append(asset_entry)\n",
    "\n",
    "# Process df_anleihen_clean, df_indices, and df_festgeld_tagesgeld_yearly\n",
    "process_columns(df_inflation, \"Anleihe\", date_column_name=\"date\")\n",
    "process_columns(df_indices, \"Index\", date_column_name=\"date\")\n",
    "process_columns(df_festgeld, \"Festgeld\", date_column_name=\"date\")\n",
    "process_columns(df_tagesgeld, \"Tagesgeld\", date_column_name=\"date\")\n",
    "process_columns(df_etf, \"ETF\", date_column_name=\"date\")\n",
    "\n",
    "# Save the JSON structure to a file\n",
    "with open(\"export/data.json\", \"w\") as json_file:\n",
    "    json.dump(json_structure, json_file, separators=(\",\", \":\"), default=convert_numpy_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
