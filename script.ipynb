{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c9a2fb",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9fe259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e901aa1",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3fcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical data\n",
    "file_path_anleihen_etf = \"./data/Anleihen und Indizes historische Zinsen.xlsx\"\n",
    "file_path_festgeld_tagesgeld = \"./data/Handelsblatt_Spezial.xlsx\"\n",
    "file_path_inflation = \"./data/Inflation_historisch_final.xlsx\"\n",
    "\n",
    "df_anleihen = pd.read_excel(file_path_anleihen_etf, sheet_name=\"Anleihen\", skiprows=2)\n",
    "df_etf = pd.read_excel(file_path_anleihen_etf, sheet_name=\"Indizes\")\n",
    "df_festgeld_tagesgeld= pd.read_excel(file_path_festgeld_tagesgeld, sheet_name=\"Monatswert\", skiprows=1)\n",
    "df_inflation= pd.read_excel(file_path_inflation, skiprows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b26b97",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaca307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Australien</th>\n",
       "      <th>Kanada</th>\n",
       "      <th>Frankreich</th>\n",
       "      <th>Deutschland</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Spanien</th>\n",
       "      <th>Schweiz</th>\n",
       "      <th>Großbritannien</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.401667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.189167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.982500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.605833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.667500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.115833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.783333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.153333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.315833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  Australien    Kanada  Frankreich  Deutschland  Japan  Spanien  \\\n",
       "0  1954         NaN       NaN         NaN          NaN    NaN      NaN   \n",
       "1  1955         NaN  3.189167         NaN          NaN    NaN      NaN   \n",
       "2  1956         NaN  3.605833         NaN          NaN    NaN      NaN   \n",
       "3  1957         NaN  4.125000         NaN     7.516667    NaN      NaN   \n",
       "4  1958         NaN  4.115833         NaN     6.783333    NaN      NaN   \n",
       "\n",
       "    Schweiz  Großbritannien       USA  \n",
       "0       NaN             NaN  2.401667  \n",
       "1  2.982500             NaN  2.816667  \n",
       "2  3.125000             NaN  3.182500  \n",
       "3  3.667500             NaN  3.647500  \n",
       "4  3.153333             NaN  3.315833  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_anleihen = df_anleihen.drop(df_anleihen.columns[[6, 11, 12, 13, 14, 15]], axis=1)\n",
    "df_anleihen.columns = [\"date\", \"Australien\", \"Kanada\", \"Frankreich\", \"Deutschland\", \"Japan\", \"Spanien\", \"Schweiz\", \"Großbritannien\", \"USA\"]\n",
    "\n",
    "df_etf.columns = [\"date\", \"Dow Jones\", \"S&P-500\", \"S&P/TSX Composite\", \"CAC 40\", \"FTSE 100\", \"Bovespa\", \"Shanghai Composite\", \"Korea Composite\", \"NIKKEI 225\", \"IBEX 35\", \"S&P/ASX 50\", \"OMX Stockholm\", \"HANG SENG\", \"BSE SENSEX\", \"Dax\", \"FTSE All\"]\n",
    "\n",
    "df_festgeld_tagesgeld = df_festgeld_tagesgeld.drop(df_festgeld_tagesgeld.columns[[8]], axis=1)\n",
    "df_festgeld_tagesgeld.columns = [\"date\", \"Festgeld_05\", \"Festgeld_1\", \"Festgeld_2\", \"Festgeld_5\", \"Festgeld_10\", \"Tagesgeld\", \"Inflation_Deutschland\"]\n",
    "\n",
    "df_inflation = df_inflation.drop(df_inflation.columns[[6, 7, 8, 9]], axis=1)\n",
    "df_inflation.columns = [\"date\", \"Australien\", \"Kanada\", \"Deutschland\", \"Frankreich\", \"Japan\", \"Spanien\", \"Schweiz\", \"Großbritannien\", \"USA\"]\n",
    "\n",
    "df_anleihen.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615aa78",
   "metadata": {},
   "source": [
    "##### Reduce Anleihen by inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3f30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the 'date' column\n",
    "df_anleihen['date'] = df_anleihen['date'].astype(str).str.extract(r'(\\d{4})')[0]\n",
    "df_inflation['date'] = df_inflation['date'].astype(str).str.extract(r'(\\d{4})')[0]\n",
    "\n",
    "# Convert the extracted year to datetime format\n",
    "df_anleihen['date'] = pd.to_datetime(df_anleihen['date'], format='%Y', errors='coerce')\n",
    "df_inflation['date'] = pd.to_datetime(df_inflation['date'], format='%Y', errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df_anleihen = df_anleihen.dropna(subset=['date'])\n",
    "df_inflation = df_inflation.dropna(subset=['date'])\n",
    "\n",
    "df_anleihen.set_index('date', inplace=True)\n",
    "df_inflation.set_index('date', inplace=True)\n",
    "\n",
    "# Reorder the columns in df_inflation to match the order of columns in df_anleihen\n",
    "df_inflation = df_inflation[df_anleihen.columns]\n",
    "\n",
    "# Subtract values in df_inflation from df_anleihen where both values exist\n",
    "df_anleihen_inflation = df_anleihen.subtract(df_inflation, fill_value=np.nan)\n",
    "\n",
    "# Reset the index to bring 'date' back as a column and convert it to year format\n",
    "df_anleihen_inflation.reset_index(inplace=True)\n",
    "df_anleihen_inflation['date'] = df_anleihen_inflation['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7009705b",
   "metadata": {},
   "source": [
    "##### Reduce Tages- & Festgeld by inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2851d17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Festgeld_05</th>\n",
       "      <th>Festgeld_1</th>\n",
       "      <th>Festgeld_10</th>\n",
       "      <th>Festgeld_2</th>\n",
       "      <th>Festgeld_5</th>\n",
       "      <th>Tagesgeld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>1.255601</td>\n",
       "      <td>1.629010</td>\n",
       "      <td>3.635168</td>\n",
       "      <td>2.358809</td>\n",
       "      <td>3.071457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995.0</td>\n",
       "      <td>1.931374</td>\n",
       "      <td>2.279073</td>\n",
       "      <td>5.138240</td>\n",
       "      <td>3.271378</td>\n",
       "      <td>4.510041</td>\n",
       "      <td>1.690489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.305996</td>\n",
       "      <td>1.461607</td>\n",
       "      <td>4.763008</td>\n",
       "      <td>2.337054</td>\n",
       "      <td>3.688200</td>\n",
       "      <td>1.275195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.829367</td>\n",
       "      <td>1.044085</td>\n",
       "      <td>3.882231</td>\n",
       "      <td>1.679422</td>\n",
       "      <td>2.852342</td>\n",
       "      <td>0.677976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>2.074893</td>\n",
       "      <td>2.310220</td>\n",
       "      <td>4.332839</td>\n",
       "      <td>2.860354</td>\n",
       "      <td>3.587562</td>\n",
       "      <td>1.756645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.966446</td>\n",
       "      <td>2.125932</td>\n",
       "      <td>4.043898</td>\n",
       "      <td>2.609831</td>\n",
       "      <td>3.296242</td>\n",
       "      <td>1.683815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.925889</td>\n",
       "      <td>2.245995</td>\n",
       "      <td>4.194538</td>\n",
       "      <td>2.920938</td>\n",
       "      <td>3.635598</td>\n",
       "      <td>1.410640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>1.434226</td>\n",
       "      <td>1.582802</td>\n",
       "      <td>3.058751</td>\n",
       "      <td>2.043698</td>\n",
       "      <td>2.543537</td>\n",
       "      <td>1.163418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2002.0</td>\n",
       "      <td>1.249279</td>\n",
       "      <td>1.478143</td>\n",
       "      <td>3.351631</td>\n",
       "      <td>2.021159</td>\n",
       "      <td>2.760313</td>\n",
       "      <td>1.054176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.918918</td>\n",
       "      <td>1.031854</td>\n",
       "      <td>3.074446</td>\n",
       "      <td>1.388819</td>\n",
       "      <td>2.207701</td>\n",
       "      <td>0.949165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  Festgeld_05  Festgeld_1  Festgeld_10  Festgeld_2  Festgeld_5  \\\n",
       "0  1994.0     1.255601    1.629010     3.635168    2.358809    3.071457   \n",
       "1  1995.0     1.931374    2.279073     5.138240    3.271378    4.510041   \n",
       "2  1996.0     1.305996    1.461607     4.763008    2.337054    3.688200   \n",
       "3  1997.0     0.829367    1.044085     3.882231    1.679422    2.852342   \n",
       "4  1998.0     2.074893    2.310220     4.332839    2.860354    3.587562   \n",
       "5  1999.0     1.966446    2.125932     4.043898    2.609831    3.296242   \n",
       "6  2000.0     1.925889    2.245995     4.194538    2.920938    3.635598   \n",
       "7  2001.0     1.434226    1.582802     3.058751    2.043698    2.543537   \n",
       "8  2002.0     1.249279    1.478143     3.351631    2.021159    2.760313   \n",
       "9  2003.0     0.918918    1.031854     3.074446    1.388819    2.207701   \n",
       "\n",
       "   Tagesgeld  \n",
       "0        NaN  \n",
       "1   1.690489  \n",
       "2   1.275195  \n",
       "3   0.677976  \n",
       "4   1.756645  \n",
       "5   1.683815  \n",
       "6   1.410640  \n",
       "7   1.163418  \n",
       "8   1.054176  \n",
       "9   0.949165  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'date' column to datetime format\n",
    "df_festgeld_tagesgeld['date'] = pd.to_datetime(df_festgeld_tagesgeld['date'])\n",
    "\n",
    "# Extract the year from the 'date' column\n",
    "df_festgeld_tagesgeld['year'] = df_festgeld_tagesgeld['date'].dt.year\n",
    "\n",
    "# Convert all columns except 'date' and 'year' to numeric, coercing errors to NaN\n",
    "numeric_columns = df_festgeld_tagesgeld.columns.difference(['date', 'year'])\n",
    "df_festgeld_tagesgeld[numeric_columns] = df_festgeld_tagesgeld[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Group by year and calculate the yearly values\n",
    "def calculate_yearly_growth(group):\n",
    "    results = {}\n",
    "    for column in group.columns:\n",
    "        count = group[column].count()\n",
    "        if count == 0:  \n",
    "            results[column] = np.nan\n",
    "        else:\n",
    "            results[column] = (np.prod(group[column].dropna() + 1) ** (1 / count)) - 1\n",
    "    return pd.Series(results)\n",
    "\n",
    "# Group by year and calculate the yearly values\n",
    "df_festgeld_tagesgeld_yearly = df_festgeld_tagesgeld.groupby('year')[numeric_columns].apply(calculate_yearly_growth).reset_index()\n",
    "\n",
    "# Subtract the value in 'Inflation_Deutschland' from every other column in the same row\n",
    "df_festgeld_tagesgeld_yearly[numeric_columns] = df_festgeld_tagesgeld_yearly[numeric_columns].sub(\n",
    "    df_festgeld_tagesgeld_yearly['Inflation_Deutschland'], axis=0\n",
    ")\n",
    "\n",
    "# Drop the 'Inflation_Deutschland' column\n",
    "df_festgeld_tagesgeld_yearly = df_festgeld_tagesgeld_yearly.drop(columns=['Inflation_Deutschland'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_festgeld_tagesgeld_yearly.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c564d5",
   "metadata": {},
   "source": [
    "##### Reduce Indices by inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34942957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Dow Jones</th>\n",
       "      <th>S&amp;P-500</th>\n",
       "      <th>S&amp;P/TSX Composite</th>\n",
       "      <th>CAC 40</th>\n",
       "      <th>FTSE 100</th>\n",
       "      <th>Bovespa</th>\n",
       "      <th>Shanghai Composite</th>\n",
       "      <th>Korea Composite</th>\n",
       "      <th>NIKKEI 225</th>\n",
       "      <th>IBEX 35</th>\n",
       "      <th>S&amp;P/ASX 50</th>\n",
       "      <th>OMX Stockholm</th>\n",
       "      <th>HANG SENG</th>\n",
       "      <th>BSE SENSEX</th>\n",
       "      <th>Dax</th>\n",
       "      <th>FTSE All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955-01-01</td>\n",
       "      <td>19.725328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.911374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.825620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956-01-01</td>\n",
       "      <td>0.746585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.786617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.479977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957-01-01</td>\n",
       "      <td>-16.109536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-26.856293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.473008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958-01-01</td>\n",
       "      <td>31.219926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.014762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.179984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1959-01-01</td>\n",
       "      <td>15.388527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.653857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1960-01-01</td>\n",
       "      <td>-10.800593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.322538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.615863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1961-01-01</td>\n",
       "      <td>17.642033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.586984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.522955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1962-01-01</td>\n",
       "      <td>-12.009288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.452037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.048278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1963-01-01</td>\n",
       "      <td>15.759257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.480708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.385689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.939091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1964-01-01</td>\n",
       "      <td>13.293472</td>\n",
       "      <td>11.690963</td>\n",
       "      <td>20.183712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.669039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.325748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Dow Jones    S&P-500  S&P/TSX Composite  CAC 40  FTSE 100  \\\n",
       "0 1955-01-01  19.725328        NaN          22.911374     NaN       NaN   \n",
       "1 1956-01-01   0.746585        NaN           3.786617     NaN       NaN   \n",
       "2 1957-01-01 -16.109536        NaN         -26.856293     NaN       NaN   \n",
       "3 1958-01-01  31.219926        NaN          24.014762     NaN       NaN   \n",
       "4 1959-01-01  15.388527        NaN           0.335578     NaN       NaN   \n",
       "5 1960-01-01 -10.800593        NaN          -3.322538     NaN       NaN   \n",
       "6 1961-01-01  17.642033        NaN          27.586984     NaN       NaN   \n",
       "7 1962-01-01 -12.009288        NaN         -11.452037     NaN       NaN   \n",
       "8 1963-01-01  15.759257        NaN          10.480708     NaN       NaN   \n",
       "9 1964-01-01  13.293472  11.690963          20.183712     NaN       NaN   \n",
       "\n",
       "   Bovespa  Shanghai Composite  Korea Composite  NIKKEI 225  IBEX 35  \\\n",
       "0      NaN                 NaN              NaN   19.825620      NaN   \n",
       "1      NaN                 NaN              NaN   27.479977      NaN   \n",
       "2      NaN                 NaN              NaN  -17.473008      NaN   \n",
       "3      NaN                 NaN              NaN   38.179984      NaN   \n",
       "4      NaN                 NaN              NaN   30.653857      NaN   \n",
       "5      NaN                 NaN              NaN   53.615863      NaN   \n",
       "6      NaN                 NaN              NaN    4.522955      NaN   \n",
       "7      NaN                 NaN              NaN   -2.048278      NaN   \n",
       "8      NaN                 NaN              NaN  -14.385689      NaN   \n",
       "9      NaN                 NaN              NaN   -2.669039      NaN   \n",
       "\n",
       "   S&P/ASX 50  OMX Stockholm  HANG SENG  BSE SENSEX  Dax   FTSE All  \n",
       "0         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "1         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "2         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "3         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "4         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "5         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "6         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "7         NaN            NaN        NaN         NaN  NaN        NaN  \n",
       "8         NaN            NaN        NaN         NaN  NaN  13.939091  \n",
       "9         NaN            NaN        NaN         NaN  NaN -11.325748  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the 'date' column exists in both DataFrames\n",
    "if 'date' not in df_etf.columns:\n",
    "    df_etf.reset_index(inplace=True)\n",
    "if 'date' not in df_inflation.columns:\n",
    "    df_inflation.reset_index(inplace=True)\n",
    "\n",
    "# Ensure the 'date' column in df_etf is in datetime format and matches the format in df_inflation\n",
    "df_etf['date'] = pd.to_datetime(df_etf['date'], format='%Y')  # Convert year-only format to datetime\n",
    "df_etf['date'] = df_etf['date'].dt.strftime('%Y-01-01')  # Standardize to 'YYYY-01-01'\n",
    "df_etf['date'] = pd.to_datetime(df_etf['date'])  # Convert back to datetime\n",
    "\n",
    "# Ensure the 'date' column in df_inflation is in datetime format\n",
    "df_inflation['date'] = pd.to_datetime(df_inflation['date'])\n",
    "\n",
    "# Merge df_etf with the 'USA' column of df_inflation on the 'date' column\n",
    "df_etf = pd.merge(df_etf, df_inflation[['date', 'USA']], on='date', how='left')\n",
    "\n",
    "# Subtract the 'USA' column from all other columns in df_etf\n",
    "numeric_columns_etf = df_etf.columns.difference(['date', 'USA'])\n",
    "df_etf[numeric_columns_etf] = df_etf[numeric_columns_etf].sub(df_etf['USA'], axis=0)\n",
    "\n",
    "# Drop the 'USA' column after adjustment\n",
    "df_etf = df_etf.drop(columns=['USA'])\n",
    "\n",
    "# Display the reduced DataFrame\n",
    "df_etf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fafca9",
   "metadata": {},
   "source": [
    "## Restructuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be72d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid values for column 'Australien' and year = 1. Skipping...\n",
      "No valid values for column 'Australien' and year = 2. Skipping...\n",
      "No valid values for column 'Australien' and year = 3. Skipping...\n",
      "No valid values for column 'Australien' and year = 4. Skipping...\n",
      "No valid values for column 'Australien' and year = 5. Skipping...\n",
      "No valid values for column 'Australien' and year = 6. Skipping...\n",
      "No valid values for column 'Australien' and year = 7. Skipping...\n",
      "No valid values for column 'Australien' and year = 8. Skipping...\n",
      "No valid values for column 'Australien' and year = 9. Skipping...\n",
      "No valid values for column 'Australien' and year = 10. Skipping...\n",
      "No valid values for column 'Australien' and year = 11. Skipping...\n",
      "No valid values for column 'Australien' and year = 12. Skipping...\n",
      "No valid values for column 'Australien' and year = 13. Skipping...\n",
      "No valid values for column 'Australien' and year = 14. Skipping...\n",
      "No valid values for column 'Australien' and year = 15. Skipping...\n",
      "No valid values for column 'Australien' and year = 16. Skipping...\n",
      "No valid values for column 'Australien' and year = 17. Skipping...\n",
      "No valid values for column 'Australien' and year = 18. Skipping...\n",
      "No valid values for column 'Australien' and year = 19. Skipping...\n",
      "No valid values for column 'Australien' and year = 20. Skipping...\n",
      "No valid values for column 'Australien' and year = 21. Skipping...\n",
      "No valid values for column 'Australien' and year = 22. Skipping...\n",
      "No valid values for column 'Australien' and year = 23. Skipping...\n",
      "No valid values for column 'Australien' and year = 24. Skipping...\n",
      "No valid values for column 'Australien' and year = 25. Skipping...\n",
      "No valid values for column 'Australien' and year = 26. Skipping...\n",
      "No valid values for column 'Australien' and year = 27. Skipping...\n",
      "No valid values for column 'Australien' and year = 28. Skipping...\n",
      "No valid values for column 'Australien' and year = 29. Skipping...\n",
      "No valid values for column 'Australien' and year = 30. Skipping...\n"
     ]
    }
   ],
   "source": [
    "# Define the range of years\n",
    "year_range = range(1, 31)  \n",
    "\n",
    "# Initialize the structure for the JSON\n",
    "json_structure = {\n",
    "    \"assets\": []\n",
    "}\n",
    "\n",
    "# Define the function to convert numpy types and pandas.Timestamp to native Python types for JSON serialization\n",
    "def convert_numpy_types(obj):\n",
    "    if isinstance(obj, (np.int64, np.int32)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float64, np.float32)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, pd.Timestamp):  \n",
    "        return obj.strftime('%Y')  \n",
    "    else:\n",
    "        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "# Function to process columns and add them to the JSON structure\n",
    "def process_columns(df, category, date_column_name=\"date\"):\n",
    "    for column_name in df.columns:\n",
    "        if column_name == date_column_name:\n",
    "            continue  \n",
    "\n",
    "        growth_column = df[column_name]\n",
    "        date_column = df[date_column_name]\n",
    "\n",
    "        # Determine the category dynamically for Festgeld and Tagesgeld\n",
    "        if \"Festgeld\" in column_name:\n",
    "            column_category = \"Festgeld\"\n",
    "        elif \"Tagesgeld\" in column_name:\n",
    "            column_category = \"Tagesgeld\"\n",
    "        else:\n",
    "            column_category = category  \n",
    "\n",
    "        # Add a new asset entry for the current column\n",
    "        asset_entry = {\n",
    "            \"category\": column_category,\n",
    "            \"label\": f\"{column_name}\",\n",
    "            \"kennung\": f\"{column_category} {column_name}\",\n",
    "            \"id\": f\"{column_category}_{column_name}\",\n",
    "            \"data\": [] \n",
    "        }\n",
    "\n",
    "        # Iterate through all values of year\n",
    "        for year in year_range:\n",
    "            \n",
    "            highest_value = float('-inf')\n",
    "            lowest_value = float('inf')\n",
    "            highest_year = None\n",
    "            lowest_year = None\n",
    "            highest_values_list = []  \n",
    "            lowest_values_list = [] \n",
    "            median_values_list = []  \n",
    "            values_with_years = [] \n",
    "\n",
    "            # Iterate through all rows where there are numbers\n",
    "            valid_growths = growth_column.dropna()\n",
    "            valid_dates = date_column[~growth_column.isna()]  \n",
    "\n",
    "            for i in range(len(valid_growths) - year + 1): \n",
    "                value = 1\n",
    "                growth_array = [] \n",
    "                for growth in valid_growths[i:i + year]:\n",
    "                    value *= (1 + growth / 100)  \n",
    "                    growth_array.append(round(growth, 2))  \n",
    "                \n",
    "                values_with_years.append((value, valid_dates.iloc[i], growth_array))  \n",
    "                if value > highest_value:\n",
    "                    highest_value = value\n",
    "                    highest_year = valid_dates.iloc[i]\n",
    "                    highest_values_list = growth_array  \n",
    "                if value < lowest_value:\n",
    "                    lowest_value = value\n",
    "                    lowest_year = valid_dates.iloc[i]\n",
    "                    lowest_values_list = growth_array  \n",
    "\n",
    "            # Calculate the median value and find its corresponding year and array\n",
    "            if values_with_years:  \n",
    "                sorted_values = sorted(values_with_years, key=lambda v: v[0])\n",
    "                median_index = len(sorted_values) // 2\n",
    "                median_value, median_year, median_values_list = sorted_values[median_index]\n",
    "\n",
    "                # Create dictionaries for max, median, and min arrays\n",
    "                max_dict = {\n",
    "                    \"type\": \"max\",\n",
    "                    \"duration\": year, \n",
    "                    \"year\": highest_year,  \n",
    "                    \"growth_array\": highest_values_list\n",
    "                }\n",
    "                median_dict = {\n",
    "                    \"type\": \"median\",\n",
    "                    \"duration\": year,  \n",
    "                    \"year\": median_year, \n",
    "                    \"growth_array\": median_values_list\n",
    "                }\n",
    "                min_dict = {\n",
    "                    \"type\": \"min\",\n",
    "                    \"duration\": year, \n",
    "                    \"year\": lowest_year, \n",
    "                    \"growth_array\": lowest_values_list\n",
    "                }\n",
    "\n",
    "                # Append the dictionaries to the \"data\" key in the asset entry\n",
    "                asset_entry[\"data\"].extend([max_dict, median_dict, min_dict])\n",
    "            else:\n",
    "                print(f\"No valid values for column '{column_name}' and year = {year}. Skipping...\")\n",
    "\n",
    "        # Append the asset entry to the JSON structure\n",
    "        json_structure[\"assets\"].append(asset_entry)\n",
    "\n",
    "# Reset the index to bring 'date' back as a column in df_anleihen_clean\n",
    "df_anleihen_inflation.reset_index(inplace=True)\n",
    "\n",
    "# Ensure the 'year' column exists in df_festgeld_tagesgeld_yearly\n",
    "if 'year' not in df_festgeld_tagesgeld_yearly.columns:\n",
    "    df_festgeld_tagesgeld_yearly.reset_index(inplace=True)\n",
    "\n",
    "# Process df_anleihen_clean, df_etf, and df_festgeld_tagesgeld_yearly\n",
    "process_columns(df_anleihen_inflation, \"Anleihe\", date_column_name=\"date\")\n",
    "process_columns(df_etf, \"Index\", date_column_name=\"date\")\n",
    "process_columns(df_festgeld_tagesgeld_yearly, \"Festgeld_Tagesgeld\", date_column_name=\"year\")\n",
    "\n",
    "# Save the JSON structure to a file\n",
    "with open(\"export/data.json\", \"w\") as json_file:\n",
    "    json.dump(json_structure, json_file, separators=(\",\", \":\"), default=convert_numpy_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
